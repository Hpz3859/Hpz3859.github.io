# 数据分析项目实战——淘宝用户行为分析



[TOC]

## 1. 数据与项目说明

### 1.1 数据说明

[淘宝用户购物行为数据集_数据集-阿里云天池](https://tianchi.aliyun.com/dataset/649)


本数据集包含了2017年11月25日至2017年12月3日之间，有行为的约一百万随机用户的所有行为（行为包括点击、购买、加购、喜欢）。数据集的组织形式和MovieLens-20M类似，即数据集的每一行表示一条用户行为，由用户ID、商品ID、商品类目ID、行为类型和时间戳组成，并以逗号分隔。关于数据集中每一列的详细描述如下：

| 列名称     | 说明                                               |
| :--------- | :------------------------------------------------- |
| 用户ID     | 整数类型，序列化后的用户ID                         |
| 商品ID     | 整数类型，序列化后的商品ID                         |
| 商品类目ID | 整数类型，序列化后的商品所属类目ID                 |
| 行为类型   | 字符串，枚举类型，包括('pv', 'buy', 'cart', 'fav') |
| 时间戳     | 行为发生的时间戳                                   |

注意到，用户行为类型共有四种，它们分别是

| 行为类型 | 说明                     |
| :------- | :----------------------- |
| pv       | 商品详情页pv，等价于点击 |
| buy      | 商品购买                 |
| cart     | 将商品加入购物车         |
| fav      | 收藏商品                 |

关于数据集大小的一些说明如下

| 维度         | 数量        |
| :----------- | :---------- |
| 用户数量     | 987,994     |
| 商品数量     | 4,162,024   |
| 用户数量     | 987,994     |
| 商品类目数量 | 9,439       |
| 所有行为数量 | 100,150,807 |

### 1.2 项目说明

本项目参考[《MySQL实战》项目文档 | LuSuZi](https://lusuzi.com/tech/mysql-practice-project-doc/)和[使用MySQL进行数据分析——以淘宝用户数据为例_利用mysql做简单分析-CSDN博客](https://blog.csdn.net/qiyamoqi/article/details/118634076)

在此基础上增加细节讲解、改进、分析



## 2. 数据预处理

### 2.1 python数据预处理

因为实战中用MySQL预处理1亿条多数据时，查空查重老是超时，所以在导入前先用Python进行数据预处理

```python
import csv

input_file = 'D:/MySQL/MySQL_projects/taobao/UserBehavior.csv'

# 读取文件到dataframe，分别给每列命名为user_id, item_id, category_id, behavior, timestamp
import pandas as pd
data = pd.read_csv(input_file, header=None, names=['user_id', 'item_id', 'category_id', 'behavior', 'timestamp'])


## 时间戳处理
# 将数据按照timestamp的顺序排序
data = data.sort_values(by=['timestamp'])

# 将timestamp转换为datetime格式
data['datetimes'] = pd.to_datetime(data['timestamp'], unit='s')
# 将日期和时间分开
data['date'] = data['datetimes'].dt.date
# 将时间转换为小时
data['hour'] = data['datetimes'].dt.hour
# 只保留需要的列
data = data[['user_id', 'item_id', 'category_id', 'behavior','datetimes', 'date', 'hour']]

# 查看数据的前几行
data.head()
```

```python
# 查找空值
data.isnull().sum()
```

<img src="D:\Github\Hpz3859.github.io\images\mysql_taobao\图2.png" alt="图2" style="zoom: 67%;" />



```python
# 查找重复值，即所有列都相同的行
data.duplicated().sum()
```

49

```python
# 去除重复值
data = data.drop_duplicates()

# 去除 不在'2017-11-25 00:00:00'和'2017-12-03 23:59:59'之间的数据
data = data[(data['datetimes'] >= '2017-11-25 00:00:00') & (data['datetimes'] <= '2017-12-03 23:59:59')]

# 计算列数
data.shape[0]
```

98914533

```python
# 重新设置索引
data = data.reset_index(drop=True)

# 增加id列，从1自增
data['id'] = range(1, data.shape[0] + 1)
data.head()

```

<img src="D:\Github\Hpz3859.github.io\images\mysql_taobao\图3.png" alt="图3" style="zoom:50%;" />

- 为什么需要自增一列id？

  因为在实战中发现，设置没有主键，会导致后续查询结果非常非常慢，而等导入1亿多条数据之后再ALTER表设自增列，运行非常慢，我的电脑跑不动，所以我在python数据预处理中就先设了自增列

```python
# 将数据保存到新的csv文件中
output_file = 'D:/MySQL/MySQL_projects/taobao/UserBehavior_processed.csv'
data.to_csv(output_file, index=False)
```

### 2.2 MySQL数据预处理

如果电脑性能可以，也可以尝试用MySQL进行数据处理

```mysql
-- 数据预处理
-- 检查空值

-- 粗略检查空值
SELECT COUNT(*) FROM user_behavior WHERE user_id IS NULL;   -- user_id无空值
SELECT COUNT(*) FROM user_behavior WHERE item_id IS NULL;	-- item_id无空值
SELECT COUNT(*) FROM user_behavior WHERE category_id IS NULL;	
SELECT COUNT(*) FROM user_behavior WHERE behavior_type IS NULL;
SELECT COUNT(*) FROM user_behavior WHERE times IS NULL;

-- 如有空值，检查具体的
select user_id,item_id from user_behavior where user_id is null;
select user_id,item_id from user_behavior where item_id is null;
select user_id,item_id,category_id from user_behavior where category_id is null;
select user_id,item_id,behavior_type from user_behavior where behavior_type is null;
select user_id,item_id,times from user_behavior where times is null;

-- 检查重复值
select user_id,item_id,times from user_behavior
group by user_id,item_id,times
having count(*)>1;

-- 查看重复值详情（因为先用python处理过重复值，这里有重复值就感觉很奇怪）
select user_id,item_id,behavior_type,times
from user_behavior
where user_id=625642 and item_id=1149592 and times = 1512229143;

-- 如果有重复值，则去重
delete user_behavior 
from user_behavior,
(
	select user_id,item_id,times from user_behavior
	group by user_id,item_id,times
	having count(*)>1
    ) dup
where user_behavior.user_id = dup.user_id
	and user_behavior.item_id = dup.item_id
    and user_behavior.times = dup.times
    and user_behavior.id > dup.id
;

```



## 3. 数据导入

### 3.1 普通代码导入

```mysql
CREATE DATABASE taobao;
use taobao;

DROP TABLE IF EXISTS user_behavior;
CREATE TABLE user_behavior (
	id int primary key,
    user_id INT,
    item_id INT,
    category_id INT,
    behavior_type VARCHAR(5),
    times int
);


LOAD DATA INFILE 'D:/MySQL/MySQL Server 8.0/Uploads/UserBehavior_clean.csv' 
INTO TABLE user_behavior 
FIELDS TERMINATED BY ','
ENCLOSED BY '"'
LINES TERMINATED BY '\n'
IGNORE 1 ROWS;

-- 设置表index提升搜索速度
ALTER TABLE user_behavior ADD INDEX idx_user_id (user_id); -- 141s
CREATE INDEX idx_item_id ON user_behavior (item_id);		-- 154s
CREATE INDEX idx_category_id ON user_behavior (category_id); -- 165s
CREATE INDEX idx_behavior_type ON user_behavior (behavior_type);  -- 191s
CREATE INDEX idx_times ON user_behavior (times); -- 160s


select count(1) from user_behavior;

desc user_behavior;
```

<img src="D:\Github\Hpz3859.github.io\images\mysql_taobao\图4.png" alt="图4" style="zoom: 80%;" />

<img src="D:\Github\Hpz3859.github.io\images\mysql_taobao\图5.png" alt="图5" style="zoom:50%;" />

#### MySQL参数设置

我在尝试寻找空值：

```
select * from user_behavior where user_id is null;
```

返回

<font color=red>Error Code: 2013. Lost connection to MySQL server during query</font>

可能的原因有：

1. **查询超时**

```mysql
SHOW VARIABLES LIKE 'wait_timeout';
SHOW VARIABLES LIKE 'interactive_timeout';
SHOW VARIABLES LIKE 'net_read_timeout';
SHOW VARIABLES LIKE 'connect_timeout';
```

如果这些时间设定得过短，可以增加到如下：

```mysql
SET GLOBAL wait_timeout = 600;
SET GLOBAL interactive_timeout = 600;
SET GLOBAL net_read_timeout = 600;
SET GLOBAL connect_timeout = 600;
```

但是更改设定之后，问题仍然没被解决，说明问题另有原因。

2. **数据量过大，服务器资源限制**

```mysql
-- 查询缓冲池
SHOW VARIABLES LIKE 'innodb_buffer_pool_size';		-- 查询
```

以我的电脑为例，第一句查询返回的默认设置是128MB，这个设置对于处理包含1亿条数据的表来说是<font color=red>过小的</font>

```
 'innodb_buffer_pool_size', '134217728'
```

- `134217728` 是 128MB 的原因是因为它表示的是字节数（Bytes）。在计算机中，1MB（兆字节）等于 \(1024 \times 1024\) 字节（Bytes），因此可以通过以下计算来验证：

$$
128 \text{MB} = 128 \times 1024 \times 1024 \text{ Bytes} = 134217728 \text{ Bytes}
$$

- 在计算机存储中，单位换算关系如下：

  **1KB（千字节）** = 1024 字节（Bytes）

  **1MB（兆字节）** = 1024KB = \(1024 \times 1024\) 字节

  **1GB（吉字节）** = 1024MB = \(1024 \times 1024 \times 1024\) 字节

- 在 MySQL 中，配置文件和命令行中通常直接使用字节数（Bytes）来表示内存大小。例如：`1024` 表示 1KB，`1048576` 表示 1MB，`1073741824` 表示 1GB

- `innodb_buffer_pool_size` 指定了 InnoDB 存储引擎用于缓存表数据和索引的内存量。简单来说，它是一个内存区域，InnoDB 会将最近访问的数据和索引存储在这里，以便后续的查询可以直接从内存中读取，而无需每次都从磁盘读取。

- `innodb_buffer_pool_size` 的设置对数据库性能有着直接的影响：

  **设置过小**

  - **性能瓶颈**：如果 `innodb_buffer_pool_size` 设置过小，缓存空间有限，无法容纳足够的数据和索引，导致频繁的磁盘 I/O 操作，查询性能会显著下降。
  - **高延迟**：对于大型表或高并发查询，每次查询都需要从磁盘读取数据，响应时间会变长，用户体验变差。

  **设置过大**

  - **内存不足**：如果 `innodb_buffer_pool_size` 设置过大，可能会占用过多的系统内存，导致其他应用程序或操作系统本身可用内存不足，从而引发内存交换（swap）。
  - **内存交换（Swap）**：当系统内存不足时，操作系统会将部分内存数据交换到磁盘上，这会进一步降低数据库性能，甚至可能导致系统崩溃。

```mysql
SET GLOBAL innodb_buffer_pool_size = 4294967296;	-- 设定为4G
```

以我的电脑为例，内存为16G，我将缓冲池大小设置为4G（因为1亿条数据的csv文件大小为3G，所以我估摸着设置了4G）

问题得以解决



#### 截取5百万条数据做后续分析

因为硬件条件一般，后续分析中跑完整的1亿条数据时间过长，容易爆内存，<font color=red>故决定只截取五百万条数据完成后续分析</font>，截取方式按照user_id排序截取，确保截取到的单个用户的行为尽可能完整

```mysql
-- 原数据量实在是太大了，所以随机抽取5000000条做项目
drop table user_behavior2;
create table user_behavior2 like user_behavior;
-- 截取 
INSERT INTO user_behavior2
SELECT * 
FROM user_behavior
ORDER BY user_id, times
;


-- 创建临时表，做测试用
create table temp_behavior like user_behavior;

-- 截取 
INSERT INTO temp_behavior
SELECT * 
FROM user_behavior
ORDER BY RAND() -- 随机
LIMIT 100000;

select * from temp_behavior;
```

#### 分区的可能、MySQL中的循环

在实战尝试中，为了保持数据完整性，我尝试过对初始表进行分区，确实能解决爆内存的问题，可是我按照日期分区后，对于在单个user_id的分组查询任务反而会降低效用，只能循环每一个分区查得分组的user_id后再把表上下连接到一起，故放弃用分区表完成整个分析。以下是我对分区的尝试，以及自动化循环每个分区查询的实现：

```mysql
-- 创建分区表
CREATE TABLE user_behavior (
	id int,
    user_id INT,
    item_id INT,
    category_id INT,
    behavior_type VARCHAR(5),
    datetimes datetime,
    dates date,
    hours int,
    PRIMARY KEY (`id`, `dates`)
) 
PARTITION BY RANGE COLUMNS(dates) (
    PARTITION p0 VALUES LESS THAN ('2017-11-26'),
    PARTITION p1 VALUES LESS THAN ('2017-11-27'),
    PARTITION p2 VALUES LESS THAN ('2017-11-28'),
    PARTITION p3 VALUES LESS THAN ('2017-11-29'),
    PARTITION p4 VALUES LESS THAN ('2017-11-30'),
    PARTITION p5 VALUES LESS THAN ('2017-12-01'),
    PARTITION p6 VALUES LESS THAN ('2017-12-02'),
    PARTITION p7 VALUES LESS THAN ('2017-12-03'),
    PARTITION p8 VALUES LESS THAN MAXVALUE
);

-- 通过 INFORMATION_SCHEMA 查询表分区
SELECT PARTITION_NAME 
FROM INFORMATION_SCHEMA.PARTITIONS 
WHERE TABLE_NAME = 'user_behavior' AND PARTITION_NAME IS NOT NULL;

-- ########################################################################
-- 浏览深度 pv/uv

-- 循环读取各个分区，自动化处理（使用存储过程）
drop PROCEDURE pv_pu_partitions;

DELIMITER $$

CREATE PROCEDURE pv_pu_partitions()
BEGIN
    DECLARE done INT DEFAULT False;
    DECLARE p VARCHAR(64);
    DECLARE cur CURSOR FOR (
    SELECT PARTITION_NAME 
    FROM INFORMATION_SCHEMA.PARTITIONS 
    WHERE 
        TABLE_NAME = 'user_behavior' 
        AND PARTITION_NAME IS NOT NULL
        AND TABLE_SCHEMA = 'taobao_p' 
);
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = True;

    -- 创建临时表存储结果
    DROP TEMPORARY TABLE IF EXISTS temp_result;
	CREATE TEMPORARY TABLE temp_result (
		dates DATE,
		hours INT,
		pv INT,
		uv INT
	);

    OPEN cur;

    read_loop: LOOP
        FETCH cur INTO p;
        IF done THEN
            LEAVE read_loop;
        END IF;

        -- 动态拼接 SQL 并执行
        SET @sql = CONCAT(
            "INSERT INTO temp_result ",
            "SELECT dates, hours, SUM(IF(behavior_type = 'pv', 1, 0)) AS pv, COUNT(DISTINCT user_id) AS uv ",
            "FROM user_behavior PARTITION (", p, ") ",
            "GROUP BY dates, hours"
        );
        PREPARE stmt FROM @sql;
        EXECUTE stmt;
        DEALLOCATE PREPARE stmt;
    END LOOP;

    CLOSE cur;
END$$

DELIMITER ;

-- 调用process_partitions
call pv_pu_partitions; -- 187s

SELECT * FROM temp_result;

DROP TEMPORARY TABLE IF EXISTS temp_result;
select * from pv_uv;
```



### 3.2 kettle方法

由于数据量非常大，用workbench导入都会卡顿，爆内存；用语句导入时间长又无法查看导入进度，所以根据参考文档和视频，下载并运用kettle进行数据的导入

1. jdk的下载

华为镜像：https://repo.huaweicloud.com/java/jdk/

[java JDK 8 官网下载网址/清华镜像/华为镜像_jdk8镜像下载-CSDN博客](https://blog.csdn.net/drzeno/article/details/120754220)

2. kettle

[Windows环境下Kettle 9.4 的下载安装配置和部署_kettle工具下载-CSDN博客](https://blog.csdn.net/guiliangfeng/article/details/143946632)

导入过程同视频

检查导入成功与否

```mysql
select count(1) from user_behavior;
```

## 4. 数据分析

### 4.1 获客情况

```mysql
-- 浏览深度 pv/uv
WITH daily_stats AS (
    SELECT 
        DATE(FROM_UNIXTIME(times)) AS dates,
        SUM(IF(behavior_type = 'pv', 1, 0)) AS pv,
        COUNT(DISTINCT user_id) AS uv
    FROM 
        temp_behavior
    GROUP BY 
        DATE(FROM_UNIXTIME(times))
)
SELECT 
    dates,
    pv,
    uv,
    ROUND(pv / uv, 2) AS `pv/uv`
FROM 
    daily_stats
ORDER BY 
    dates;

-- 处理真实数据
drop table pv_uv_puv;
create table pv_uv_puv(
	dates char(10),
    hours int,
    pv int,
    uv int
);


insert into pv_uv_puv
WITH daily_stats AS (
    SELECT 
        DATE(FROM_UNIXTIME(times)) AS dates,
        HOUR(FROM_UNIXTIME(times)) AS hours,
        SUM(IF(behavior_type = 'pv', 1, 0)) AS pv,
        COUNT(DISTINCT user_id) AS uv
    FROM 
        user_behavior2
    GROUP BY 
        DATE(FROM_UNIXTIME(times)),HOUR(FROM_UNIXTIME(times))
)
SELECT 
    dates,
    hours,
    pv,
    uv
FROM 
    daily_stats
ORDER BY 
    dates, hours; -- 11s
 
 select * from pv_uv_puv;
```

### 4.2 留存情况

先是用表的自关联的方式计算多日留存率，可是笛卡尔积实在是很损耗内存，故后改进用case when加左连接的方法进行计算

- 表的自关联

```mysql
-- select 
-- *
-- from 
-- (
-- 	select
-- 	user_id, 
-- 	DATE(FROM_UNIXTIME(times)) AS dates
--     from temp_behavior
-- ) a,
-- (
-- 	select
-- 	user_id, 
-- 	DATE(FROM_UNIXTIME(times)) AS dates
--     from temp_behavior
-- ) b
-- where a.user_id = b.user_id and a.dates <= b.dates;

-- -- 计算多日留存数
-- select
-- a.dates,
-- sum(if(timestampdiff(day,a.dates,b.dates)=0,1,0)) retention_0,
-- sum(if(timestampdiff(day,a.dates,b.dates)=1,1,0)) retention_1,
-- sum(if(timestampdiff(day,a.dates,b.dates)=2,1,0)) retention_2,
-- sum(if(timestampdiff(day,a.dates,b.dates)=5,1,0)) retention_5,
-- sum(if(timestampdiff(day,a.dates,b.dates)=7,1,0)) retention_7
-- from 
-- (
-- 	select
-- 	user_id, 
-- 	DATE(FROM_UNIXTIME(times)) AS dates
--     from temp_behavior
-- ) a,
-- (
-- 	select
-- 	user_id, 
-- 	DATE(FROM_UNIXTIME(times)) AS dates
--     from temp_behavior
-- ) b
-- where a.user_id = b.user_id and a.dates <= b.dates
-- group by a.dates;

-- -- 计算多日留存率
-- with retention_num as (
-- select
-- a.dates,
-- sum(if(timestampdiff(day,a.dates,b.dates)=0,1,0)) retention_0,
-- sum(if(timestampdiff(day,a.dates,b.dates)=1,1,0)) retention_1,
-- sum(if(timestampdiff(day,a.dates,b.dates)=2,1,0)) retention_2,
-- sum(if(timestampdiff(day,a.dates,b.dates)=5,1,0)) retention_5,
-- sum(if(timestampdiff(day,a.dates,b.dates)=7,1,0)) retention_7
-- from 
-- (
-- 	select
-- 	user_id, 
-- 	DATE(FROM_UNIXTIME(times)) AS dates
--     from temp_behavior
-- ) a,
-- (
-- 	select
-- 	user_id, 
-- 	DATE(FROM_UNIXTIME(times)) AS dates
--     from temp_behavior
-- ) b
-- where a.user_id = b.user_id and a.dates <= b.dates
-- group by a.dates
--     )
-- select 
-- 	dates,
--     round(retention_1 / retention_0,2) as rr_1,
--     round(retention_2 / retention_0,2) as rr_2,
--     round(retention_5 / retention_0,2) as rr_5,
--     round(retention_7 / retention_0,2) as rr_7
-- from retention_num;

```

- 窗口函数方法

```mysql
drop table retention_rate;
create table retention_rate(
	dates char(10),
	retention_1 decimal(10,2),
	retention_2 decimal(10,2),
	retention_7 decimal(10,2)
);


insert into retention_rate
WITH first_action AS (
    SELECT
        user_id,
        DATE(FROM_UNIXTIME(MIN(times))) AS first_date
    FROM user_behavior2
    GROUP BY user_id
),
retention_counts AS (
    SELECT
        fa.first_date AS first_date,
        COUNT(DISTINCT fa.user_id) AS total_users,
        COUNT(DISTINCT CASE 
            WHEN DATEDIFF(DATE(FROM_UNIXTIME(ub.times)), fa.first_date) = 1 THEN ub.user_id 
            ELSE NULL 
        END) AS next_day,
        COUNT(DISTINCT CASE 
            WHEN DATEDIFF(DATE(FROM_UNIXTIME(ub.times)), fa.first_date) = 2 THEN ub.user_id 
            ELSE NULL 
        END) AS two_day,
        COUNT(DISTINCT CASE 
            WHEN DATEDIFF(DATE(FROM_UNIXTIME(ub.times)), fa.first_date) = 7 THEN ub.user_id 
            ELSE NULL 
        END) AS seven_day
    FROM first_action fa
    LEFT JOIN user_behavior2 ub
        ON fa.user_id = ub.user_id 
        AND ub.times >= fa.first_date
    GROUP BY fa.first_date
)
SELECT
    first_date,
    ROUND(next_day / total_users * 100, 2) AS next_day_retention_rate,
    ROUND(two_day / total_users * 100, 2) AS two_day_retention_rate,
    ROUND(seven_day / total_users * 100, 2) AS seven_day_retention_rate
FROM retention_counts
ORDER BY first_date; -- 31s

select * from retention_rate;
```

### 4.3 用户行为时间分析

```mysql
-- 用户行为时间分析

-- 假设1： 用户周末更加活跃
select 
	date(from_unixtime(times)) as '日期',
    DATE_FORMAT(FROM_UNIXTIME(times), '%W') AS '星期',
    sum(case when behavior_type = 'pv' then 1 else 0 end) as '点击',
    sum(case when behavior_type = 'fav' then 1 else 0 end) as '收藏',
    sum(case when behavior_type = 'cart' then 1 else 0 end) as '加购',
    sum(case when behavior_type = 'buy' then 1 else 0 end) as '购买',
    count(behavior_type) as '总计'
from temp_behavior
group by 日期, 星期;


-- 处理真实数据
drop table week_behavior;
create table week_behavior(
	日期 char(10),
    星期 char(10),
    点击 int,
    收藏 int,
    加购 int,
    购买 int,
    总计 int
    );

insert into week_behavior
select 
	date(from_unixtime(times)) as '日期',
    DATE_FORMAT(FROM_UNIXTIME(times), '%W') AS '星期',
    sum(case when behavior_type = 'pv' then 1 else 0 end) as '点击',
    sum(case when behavior_type = 'fav' then 1 else 0 end) as '收藏',
    sum(case when behavior_type = 'cart' then 1 else 0 end) as '加购',
    sum(case when behavior_type = 'buy' then 1 else 0 end) as '购买',
    count(behavior_type) as '总计'
from user_behavior2
group by 日期, 星期
order by 日期;

select * from week_behavior;

-- 假设2：用户在下午和晚上的活跃度上升
select 
	date(from_unixtime(times)) as dates,
	hour(from_unixtime(times)) as hours,
    sum(case when behavior_type = 'pv' then 1 else 0 end) as '点击',
    sum(case when behavior_type = 'fav' then 1 else 0 end) as '收藏',
    sum(case when behavior_type = 'cart' then 1 else 0 end) as '加购',
    sum(case when behavior_type = 'buy' then 1 else 0 end) as '购买',
    count(behavior_type) as '总计'
from temp_behavior
group by dates, hours
order by dates,hours;


drop table hour_behavior;
create table hour_behavior(
	dates char(10),
	hours int,
    点击 int,
    收藏 int,
    加购 int,
    购买 int,
    总计 int
    );

insert into hour_behavior
select 
	date(from_unixtime(times)) as dates,
	hour(from_unixtime(times)) as hours,
    sum(case when behavior_type = 'pv' then 1 else 0 end) as '点击',
    sum(case when behavior_type = 'fav' then 1 else 0 end) as '收藏',
    sum(case when behavior_type = 'cart' then 1 else 0 end) as '加购',
    sum(case when behavior_type = 'buy' then 1 else 0 end) as '购买',
    count(behavior_type) as '总计'
from user_behavior2
group by dates, hours
order by dates,hours; -- 11s

select * from hour_behavior;
```

### 4.4 用户行为路径分析

```mysql
-- 用户行为路径分析

-- 分别计算出各类行为的总数

select
	behavior_type,
	count(user_id) as '行为数'
from temp_behavior
group by behavior_type
ORDER BY 
  CASE behavior_type
    WHEN 'pv' THEN 1
    WHEN 'fav' THEN 2
    WHEN 'cart' THEN 3
    ELSE 4 -- 可选：处理未列出的值
  END;
  
-- 可以看到用户不仅是直链的发展
-- 计算每个用户对每个商品的行为

-- 标准化
drop view user_behavior_standard;
create view user_behavior_standard as
with ui_behavior as (
	select
		user_id,
		item_id,
		count(if(behavior_type='pv',behavior_type,null)) as pv,  -- 因为是截断的数据, 在用户行为分析中，所以只要是出现的用户和产品都应该是浏览过的
		count(if(behavior_type='fav',behavior_type,null)) as fav,
		count(if(behavior_type='cart',behavior_type,null)) as cart,
		count(if(behavior_type='buy',behavior_type,null)) as buy
	from user_behavior2
	group by user_id, item_id
)
select
	user_id,
	item_id,
    if(pv>0 ,1,0) as pv, 
    if(fav>0,1,0) as fav,
    if(cart>0,1,0) as cart,
    if(buy>0,1,0) as buy
from ui_behavior;

drop view user_behavior_path;
create view user_behavior_path as
select
	user_id,
    item_id,
    concat(pv,fav,cart,buy) as paths
from user_behavior_standard;

-- 行为路径描述表
create table path_descrb(
paths char(4),
descriptions varchar(20));

insert into path_descrb 
values
('1000', '只浏览'),
('1100', '浏览-收藏'),
('1110', '浏览-收藏-加购'),
('1010', '浏览-加购'),
('1001', '浏览-购买'),
('1011', '浏览-加购-购买'),
('1101', '浏览-收藏-购买'),
('1111', '浏览-收藏-加购-购买');

insert into path_descrb 
values
('0100', '只收藏'),
('0001', '购买'),
('0010', '只加购'),
('0110', '收藏-加购'),
('0101', '收藏-购买'),
('0011', '加购-购买'),
('0111', '收藏-加购-购买');

select * from path_descrb;
    
-- 存储 
drop table path_result;
create table path_result(
	paths char(4),
	descriptions varchar(20),
	num int);
    
insert into path_result
SELECT 
    up.paths, 
    p.descriptions, 
    COUNT(*) AS num 
FROM 
    user_behavior_path up 
LEFT JOIN 
    path_descrb p 
ON 
    p.paths = up.paths 
GROUP BY 
    up.paths, p.descriptions; -- 45s
    
select * from path_result; 

select
	sum(num) as '总行为数'
from path_result; -- '3799395'
```



### 4.5 用户转化率分析

```mysql
-- 用户转化率分析

-- 跳失率，即只出现一次的用户
select
	user_id
from user_behavior2
group by user_id
having count(user_id) = 1;

with one_show as(
select
	user_id
from user_behavior
group by user_id
having count(user_id) = 1
)
select
	round(count(o.user_id) / count(distinct u.user_id) * 100,5) as jump_r
from user_behavior2 u 
left join one_show o on u.user_id = o.user_id;

-- 跳失率非常小，0.0082%，说明几乎无跳失，平台的用户粘性很高


-- 用户浏览后的转化率
-- 浏览-购买转化率
select 
	round(sum(if(paths REGEXP '1$',num,0))/sum(num) *100 ,2) as buy_transf
from path_result;
-- 只有2.44%的用户在浏览了商品之后选择购买，可能推荐算法有问题，推荐的东西用户只浏览，不下单

-- 进一步分析

select * from path_result;

-- 浏览-收藏转化率
select 
	round(sum(if(paths like '_1%',num,0))/sum(num) *100 ,2) as fav_transf -- paths的第二位为1，即收藏了
from path_result;
-- 只有3.73%的用户在浏览了商品之后选择收藏，可能推荐算法有问题，推荐的东西用户只浏览，不下单

-- 浏览-加购转化率
select 
	round(sum(if(paths like '__1%',num,0))/sum(num) *100 ,2) as cart_transf -- paths的第三位为1，即加购了
from path_result;
-- 只有7.23%的用户在浏览了商品之后选择收藏，可能推荐算法有问题，推荐的东西用户只浏览，不下单

-- 收藏-购买转化率
select 
	round(sum(if(paths REGEXP '1$',num,0))/sum(if(paths like '_1%',num,0)) *100 ,2) as fav_buy_transf 
from path_result;
-- 有65.44%的用户在收藏了之后选择购买

-- 加购-购买转化率
select 
	round(sum(if(paths REGEXP '1$',num,0))/sum(if(paths like '__1%',num,0)) *100 ,2) as cart_buy_transf 
from path_result;
-- 有33.76%的用户在收藏了之后选择购买

```

### 4.6 RFM分析

```mysql
-- RFM分析
-- R 最近一次消费的时间间隔，当前时间-最近一次购买时间
-- F 消费的频率，分析周期内的购买次数
-- M 消费的金额

drop view r_f_score;
create view r_f_score as
with R_F as(
	select 
		user_id, 
		datediff('2017-12-03',max(date(from_unixtime(times))))+1 R, 
		count(behavior_type) F
	from user_behavior2
	where behavior_type = 'buy'
	group by user_id
)
select *,
	 (case when R between 8 and 9 then 1
			  when R between 5 and 7 then 2
			  when R between 3 and 5 then 3
				when R <= 2 then 4 
	 end) as R_score,
	 (case when F between 1 and 6 then 1
		  when F between 7 and 12 then 2
				when F between 13 and 18 then 3
				when F >= 19 then 4
		end) as F_score
from R_F;

drop view user_type;
create view user_type as 
SELECT 
    user_id, 
    R, 
    F, 
    R_score, 
    F_score,
    CASE 
        WHEN R_score >= AVG_R_score 
             AND F_score >= AVG_F_score 
        THEN '重要价值客户'
        WHEN R_score >= AVG_R_score 
             AND F_score < AVG_F_score 
        THEN '重要发展客户'
        WHEN R_score < AVG_R_score 
             AND F_score >= AVG_F_score 
        THEN '重要保持客户'
        WHEN R_score < AVG_R_score 
             AND F_score < AVG_F_score 
        THEN '重要挽留客户'
    END AS `客户类型`
FROM (
    SELECT 
        user_id, 
        R, 
        F, 
        R_score, 
        F_score,
        AVG(R_score) OVER() AS AVG_R_score,  -- 计算整个表的平均值
        AVG(F_score) OVER() AS AVG_F_score
    FROM r_f_score
) AS subquery
;

create table user_types (
user_id int, 
`客户类型` char(10));

insert into user_types
select user_id,客户类型
from user_type
;

```

### 4.7 统计商品的热门品类、热门商品

```mysql
-- 统计商品的热门品类、热门商品、热门品类热门商品

-- 热门品类
drop view hot_category;
create view hot_category as(
    SELECT 
        category_id,
        COUNT(IF(behavior_type = 'buy', behavior_type, NULL)) AS 品类购买量
    FROM user_behavior2
    GROUP BY category_id
    ORDER BY 品类购买量 DESC
    LIMIT 10
);
-- 统计热门品类下每个商品的购买量
drop view item_purchases;
create view item_purchases AS (
    SELECT 
        hc.category_id,
        t.item_id,
        COUNT(IF(t.behavior_type = 'buy', t.behavior_type, NULL)) AS 商品购买量,
        -- 为每个品类内的商品按购买量降序排名
        ROW_NUMBER() OVER (
			PARTITION BY hc.category_id 
            ORDER BY COUNT(IF(t.behavior_type = 'buy', t.behavior_type, NULL)) DESC) AS rn
    FROM user_behavior2 t
    INNER JOIN hot_category hc ON t.category_id = hc.category_id
    GROUP BY hc.category_id, t.item_id
);

drop table hot_category_item;
create table hot_category_item(
	品类id int,
    商品id int,
    商品购买量 int
);

-- 筛选出每个品类中购买量最高的几个商品
insert into hot_category_item
SELECT 
    category_id,
    item_id,
    商品购买量
FROM item_purchases
WHERE rn <= 3
ORDER BY category_id, 商品购买量 DESC;

select * from hot_category_item;
```

### 4.8 商品转化率分析

```mysql
-- 商品转化率分析
drop table hot_item_transf;
create table hot_item_transf(
	item_id int,
    购买转化率 decimal(10,2),
    收藏转化率 decimal(10,2),
    加购转化率 decimal(10,2)
);

drop view item_behavior_count;
create view item_behavior_count as
with ui_behavior as (
	select
		user_id,
		item_id,
		count(if(behavior_type='pv',behavior_type,null)) as pv,  -- 因为是截断的数据, 在用户行为分析中，所以只要是出现的用户和产品都应该是浏览过的
		count(if(behavior_type='fav',behavior_type,null)) as fav,
		count(if(behavior_type='cart',behavior_type,null)) as cart,
		count(if(behavior_type='buy',behavior_type,null)) as buy
	from user_behavior2
	group by user_id, item_id
)
select
	item_id,
    sum(pv) as pv, 
    sum(fav) as fav,
    sum(cart) as cart,
    sum(buy) as buy
from ui_behavior
group by item_id;


INSERT INTO hot_item_transf 
SELECT 
  item_id, 
  ROUND(buy / pv  * 100, 2) AS buy_r,
  ROUND(fav / pv  * 100, 2) AS fav_r,
  ROUND(cart / pv  * 100, 2) AS cart_r
FROM item_behavior_count 
ORDER BY buy_r DESC, fav_r DESC, cart_r DESC 
;

select * from hot_item_transf;


-- 用户商品行为
create table u_i_behavior as
select
		user_id,
		item_id,
		count(if(behavior_type='pv',behavior_type,null)) as pv,  
		count(if(behavior_type='fav',behavior_type,null)) as fav,
		count(if(behavior_type='cart',behavior_type,null)) as cart,
		count(if(behavior_type='buy',behavior_type,null)) as buy
	from user_behavior2
	group by user_id, item_id; 
select * from u_i_behavior;
```

